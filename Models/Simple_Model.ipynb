{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Model de train test et split"
      ],
      "metadata": {
        "id": "lvIvy2KUw5w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "# Chemins vers les dossiers\n",
        "train_data_dir = \"/content/drive/MyDrive/ColabNotebooks/chest_Xray/train\"\n",
        "val_data_dir = \"/content/drive/MyDrive/ColabNotebooks/chest_Xray/val\"\n",
        "test_data_dir = \"/content/drive/MyDrive/ColabNotebooks/chest_Xray/test\"\n",
        "\n",
        "# Paramètres du générateur d'images\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Créer les générateurs d'images\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Charger les données d'entraînement et de validation\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Effectuer une validation croisée avec K-Fold\n",
        "k = 5  # Nombre de folds\n",
        "kf = KFold(n_splits=k)\n",
        "\n",
        "# Liste pour stocker les scores de chaque fold\n",
        "scores = []\n",
        "\n",
        "for train_index, val_index in kf.split(train_generator.filenames):\n",
        "    # Diviser les données en ensembles d'entraînement et de validation pour chaque fold\n",
        "    train_files = [train_generator.filenames[i] for i in train_index]\n",
        "    val_files = [train_generator.filenames[i] for i in val_index]\n",
        "\n",
        "    train_datagen_fold = ImageDataGenerator(rescale=1./255)\n",
        "    train_generator_fold = train_datagen_fold.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        classes=[\"NORMAL\", \"PNEUMONIA\"],\n",
        "        shuffle=False,\n",
        "        subset='training',\n",
        "        seed=42)\n",
        "\n",
        "    val_datagen_fold = ImageDataGenerator(rescale=1./255)\n",
        "    val_generator_fold = val_datagen_fold.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        classes=[\"NORMAL\", \"PNEUMONIA\"],\n",
        "        shuffle=False,\n",
        "        subset='validation',\n",
        "        seed=42)\n",
        "\n",
        "    # Créer, entraîner et évaluer le modèle pour chaque fold\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.Recall(name='recall') ])\n",
        "\n",
        "model.fit(train_generator_fold, validation_data=val_generator_fold, epochs=40, verbose=1)\n",
        "score = model.evaluate(val_generator, verbose=0)[1]  # Récupérer le score d'accuracy\n",
        "scores.append(score)\n",
        "\n",
        "# Afficher les scores de chaque fold\n",
        "for i, score in enumerate(scores):\n",
        "    print(f\"Fold {i+1} - Accuracy: {score}\")\n",
        "\n",
        "# Afficher le score moyen\n",
        "mean_score = np.mean(scores)\n",
        "print(\"Mean Accuracy:\", mean_score)\n",
        "\n",
        "# Évaluer le modèle sur les données de test\n",
        "\n",
        "test_score = model.evaluate(test_generator, verbose=0)[1]\n",
        "print(\"Test Accuracy:\", test_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuIsw5WmVbQP",
        "outputId": "3dae0793-9a43-4c26-e9bc-521ce2bbe195"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Found 5216 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Found 5216 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Found 5216 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Found 5216 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Found 5216 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Epoch 1/40\n",
            "163/163 [==============================] - 77s 453ms/step - loss: 14.7935 - accuracy: 0.6099 - recall: 0.7466\n",
            "Epoch 2/40\n",
            "163/163 [==============================] - 74s 452ms/step - loss: 0.8206 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 3/40\n",
            "163/163 [==============================] - 73s 449ms/step - loss: 0.8058 - accuracy: 0.7402 - recall: 0.9964\n",
            "Epoch 4/40\n",
            "163/163 [==============================] - 73s 445ms/step - loss: 0.6724 - accuracy: 0.7398 - recall: 0.9959\n",
            "Epoch 5/40\n",
            "163/163 [==============================] - 74s 450ms/step - loss: 0.6402 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 6/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.6301 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 7/40\n",
            "163/163 [==============================] - 73s 447ms/step - loss: 0.6215 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 8/40\n",
            "163/163 [==============================] - 72s 440ms/step - loss: 0.6142 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 9/40\n",
            "163/163 [==============================] - 73s 451ms/step - loss: 0.6078 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 10/40\n",
            "163/163 [==============================] - 72s 445ms/step - loss: 0.6024 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 11/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.5979 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 12/40\n",
            "163/163 [==============================] - 73s 447ms/step - loss: 0.5939 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 13/40\n",
            "163/163 [==============================] - 75s 461ms/step - loss: 0.5905 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 14/40\n",
            "163/163 [==============================] - 74s 454ms/step - loss: 0.5876 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 15/40\n",
            "163/163 [==============================] - 75s 459ms/step - loss: 0.5852 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 16/40\n",
            "163/163 [==============================] - 75s 459ms/step - loss: 0.5830 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 17/40\n",
            "163/163 [==============================] - 76s 470ms/step - loss: 0.5812 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 18/40\n",
            "163/163 [==============================] - 74s 455ms/step - loss: 0.5796 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 19/40\n",
            "163/163 [==============================] - 73s 451ms/step - loss: 0.5783 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 20/40\n",
            "163/163 [==============================] - 74s 449ms/step - loss: 0.5772 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 21/40\n",
            "163/163 [==============================] - 73s 448ms/step - loss: 0.5762 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 22/40\n",
            "163/163 [==============================] - 72s 442ms/step - loss: 0.5753 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 23/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.5746 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 24/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.5739 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 25/40\n",
            "163/163 [==============================] - 73s 449ms/step - loss: 0.5734 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 26/40\n",
            "163/163 [==============================] - 72s 442ms/step - loss: 0.5729 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 27/40\n",
            "163/163 [==============================] - 73s 444ms/step - loss: 0.5726 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 28/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.5723 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 29/40\n",
            "163/163 [==============================] - 72s 441ms/step - loss: 0.5720 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 30/40\n",
            "163/163 [==============================] - 72s 439ms/step - loss: 0.5717 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 31/40\n",
            "163/163 [==============================] - 72s 441ms/step - loss: 0.5716 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 32/40\n",
            "163/163 [==============================] - 72s 443ms/step - loss: 0.5713 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 33/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.5712 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 34/40\n",
            "163/163 [==============================] - 72s 442ms/step - loss: 0.5710 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 35/40\n",
            "163/163 [==============================] - 72s 440ms/step - loss: 0.5709 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 36/40\n",
            "163/163 [==============================] - 73s 447ms/step - loss: 0.5708 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 37/40\n",
            "163/163 [==============================] - 73s 447ms/step - loss: 0.5707 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 38/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.5707 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 39/40\n",
            "163/163 [==============================] - 72s 444ms/step - loss: 0.5706 - accuracy: 0.7429 - recall: 1.0000\n",
            "Epoch 40/40\n",
            "163/163 [==============================] - 72s 442ms/step - loss: 0.5706 - accuracy: 0.7429 - recall: 1.0000\n",
            "Fold 1 - Accuracy: 0.5\n",
            "Mean Accuracy: 0.5\n",
            "Test Accuracy: 0.625\n"
          ]
        }
      ]
    }
  ]
}